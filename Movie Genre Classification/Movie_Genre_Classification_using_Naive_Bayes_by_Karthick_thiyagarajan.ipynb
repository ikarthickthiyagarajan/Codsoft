{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2347441,
          "sourceType": "datasetVersion",
          "datasetId": 1417162
        }
      ],
      "dockerImageVersionId": 30558,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "import nltk\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'genre-classification-dataset-imdb:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1417162%2F2347441%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240302%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240302T084844Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D298df95e2e1294ffc990e791914dc7c0fae95015986bd8bd4bb415b82b6cd377ad8321a7cbadfc31d8b48cb70f231eb7cde7745a59e4ba72ff989d857deea14ed291e4c97d336e7a5541a35e8d02a55529357cc0479f6dc7262580dc502743a195fb84d153bbce213d38a9a540abc1c42dcd972dde7bdf60b2b0ba38e73836818d497ac7006df28af69b7056b6c655ed0673c4a132a245b2122c050073b63b71c1969e142144ea5dedaafe951240167a935967b8a3b2731c16f76ea621671a07e14d966465c434d647a862625c297c38753ce20ba29a29d6f289476141e7e57077acbb0ebf0f432a51c72aaf2a8ba7d02521f1346a6c55ce765dd7d5f349e2d6'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')"
      ],
      "metadata": {
        "id": "YHGjAG0VWgpO"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TgpkM5uAWgpV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries #"
      ],
      "metadata": {
        "id": "0zp0sxwoWgpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-02T08:48:14.51557Z",
          "iopub.execute_input": "2024-03-02T08:48:14.515944Z",
          "iopub.status.idle": "2024-03-02T08:48:17.661172Z",
          "shell.execute_reply.started": "2024-03-02T08:48:14.515915Z",
          "shell.execute_reply": "2024-03-02T08:48:17.659971Z"
        },
        "trusted": true,
        "id": "tzLjX3zAWgpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset #"
      ],
      "metadata": {
        "id": "2F3T4uxdWgpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the training data\n",
        "train_path = \"/kaggle/input/genre-classification-dataset-imdb/Genre Classification Dataset/train_data.txt\"\n",
        "train_data = pd.read_csv(train_path, sep=':::', names=['Title', 'Genre', 'Description'], engine='python')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-02T08:48:17.663372Z",
          "iopub.execute_input": "2024-03-02T08:48:17.664714Z",
          "iopub.status.idle": "2024-03-02T08:48:18.58671Z",
          "shell.execute_reply.started": "2024-03-02T08:48:17.664675Z",
          "shell.execute_reply": "2024-03-02T08:48:18.585433Z"
        },
        "trusted": true,
        "id": "UruSM24QWgpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.describe())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-02T08:48:18.588049Z",
          "iopub.execute_input": "2024-03-02T08:48:18.588735Z",
          "iopub.status.idle": "2024-03-02T08:48:18.730476Z",
          "shell.execute_reply.started": "2024-03-02T08:48:18.588702Z",
          "shell.execute_reply": "2024-03-02T08:48:18.728964Z"
        },
        "trusted": true,
        "id": "xw8oh5lLWgpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.info())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-02T08:48:18.731784Z",
          "iopub.execute_input": "2024-03-02T08:48:18.732227Z",
          "iopub.status.idle": "2024-03-02T08:48:18.775187Z",
          "shell.execute_reply.started": "2024-03-02T08:48:18.732185Z",
          "shell.execute_reply": "2024-03-02T08:48:18.773861Z"
        },
        "trusted": true,
        "id": "CGDIc30WWgph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.isnull().sum())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-02T08:48:18.779127Z",
          "iopub.execute_input": "2024-03-02T08:48:18.779481Z",
          "iopub.status.idle": "2024-03-02T08:48:18.806707Z",
          "shell.execute_reply.started": "2024-03-02T08:48:18.779454Z",
          "shell.execute_reply": "2024-03-02T08:48:18.805434Z"
        },
        "trusted": true,
        "id": "opbgL7nzWgpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test data\n",
        "test_path = \"/kaggle/input/genre-classification-dataset-imdb/Genre Classification Dataset/test_data.txt\"\n",
        "test_data = pd.read_csv(test_path, sep=':::', names=['Id', 'Title', 'Description'], engine='python')\n",
        "test_data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-02T08:48:18.808858Z",
          "iopub.execute_input": "2024-03-02T08:48:18.809349Z",
          "iopub.status.idle": "2024-03-02T08:48:19.664897Z",
          "shell.execute_reply.started": "2024-03-02T08:48:18.809303Z",
          "shell.execute_reply": "2024-03-02T08:48:19.663777Z"
        },
        "trusted": true,
        "id": "AkaRrWM1Wgpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA & Visualization #"
      ],
      "metadata": {
        "id": "yNS0nOaZWgpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the distribution of genres in the training data\n",
        "plt.figure(figsize=(14, 7))\n",
        "sns.countplot(data=train_data, y='Genre', order=train_data['Genre'].value_counts().index, palette='viridis')\n",
        "plt.xlabel('Count', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Genre', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Plot the distribution of genres using a bar plot\n",
        "plt.figure(figsize=(14, 7))\n",
        "counts = train_data['Genre'].value_counts()\n",
        "sns.barplot(x=counts.index, y=counts, palette='viridis')\n",
        "plt.xlabel('Genre', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Count', fontsize=14, fontweight='bold')\n",
        "plt.title('Distribution of Genres', fontsize=16, fontweight='bold')\n",
        "plt.xticks(rotation=90, fontsize=14, fontweight='bold')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-02T08:48:19.666282Z",
          "iopub.execute_input": "2024-03-02T08:48:19.667093Z",
          "iopub.status.idle": "2024-03-02T08:48:20.9601Z",
          "shell.execute_reply.started": "2024-03-02T08:48:19.667054Z",
          "shell.execute_reply": "2024-03-02T08:48:20.958655Z"
        },
        "trusted": true,
        "id": "05P7RiTCWgpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Data Preprocessing and Text Cleaning #"
      ],
      "metadata": {
        "id": "6DRVsASxWgpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the stemmer and stop words\n",
        "stemmer = LancasterStemmer()\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Define the clean_text function\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'@\\S+', '', text)\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'pic.\\S+', '', text)\n",
        "    text = re.sub(r\"[^a-zA-Z+']\", ' ', text)\n",
        "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text + ' ')\n",
        "    text = \"\".join([i for i in text if i not in string.punctuation])\n",
        "    words = nltk.word_tokenize(text)\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    text = \" \".join([i for i in words if i not in stopwords and len(i) > 2])\n",
        "    text = re.sub(\"\\s[\\s]+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "# Apply the clean_text function to the 'Description' column in the training and test data\n",
        "train_data['Text_cleaning'] = train_data['Description'].apply(clean_text)\n",
        "test_data['Text_cleaning'] = test_data['Description'].apply(clean_text)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-02T08:48:20.961752Z",
          "iopub.execute_input": "2024-03-02T08:48:20.962777Z"
        },
        "trusted": true,
        "id": "n3vv98zeWgpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Continue Data Preprocessing #"
      ],
      "metadata": {
        "id": "VXIukfBeWgpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the length of cleaned text\n",
        "train_data['length_Text_cleaning'] = train_data['Text_cleaning'].apply(len)\n",
        "# Visualize the distribution of text lengths\n",
        "plt.figure(figsize=(8, 7))\n",
        "sns.histplot(data=train_data, x='length_Text_cleaning', bins=20, kde=True, color='blue')\n",
        "plt.xlabel('Length', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Frequency', fontsize=14, fontweight='bold')\n",
        "plt.title('Distribution of Lengths', fontsize=16, fontweight='bold')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "yi7q2PBLWgpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Text Vectorization Using TF-IDF #"
      ],
      "metadata": {
        "id": "3NdfKgEwWgpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train = tfidf_vectorizer.fit_transform(train_data['Text_cleaning'])\n",
        "\n",
        "# Transform the test data\n",
        "X_test = tfidf_vectorizer.transform(test_data['Text_cleaning'])\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "DoLKobQXWgpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Split Data and Train a Model (Naive Bayes) #"
      ],
      "metadata": {
        "id": "j3YLkoUqWgpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and validation sets\n",
        "X = X_train\n",
        "y = train_data['Genre']\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train a Multinomial Naive Bayes classifier\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_pred = classifier.predict(X_val)\n",
        "\n",
        "# Evaluate the performance of the model\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "print(classification_report(y_val, y_pred))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "6Dbr19aZWgpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Make Predictions on the Test Data #"
      ],
      "metadata": {
        "id": "PjHm3bPcWgpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the trained model to make predictions on the test data\n",
        "X_test_predictions = classifier.predict(X_test)\n",
        "test_data['Predicted_Genre'] = X_test_predictions"
      ],
      "metadata": {
        "trusted": true,
        "id": "IJ9_UZnlWgpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the test_data DataFrame with predicted genres to a CSV file\n",
        "test_data.to_csv('predicted_genres.csv', index=False)\n",
        "\n",
        "# Display the 'test_data' DataFrame with predicted genres\n",
        "print(test_data)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "hmGKtcDlWgpn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}